# The LightJason Speeding game


### Fatema Tuj Johora & Sînziana-Maria Sebe
-----
# Lecture recap

Our agents function on a Belief-desire-intention (BDI) architecture.

M. Aschermann and P. Kraus designed a new agent language, AgentSpeak(L++). They also created the Java framework LightJason for the new language.


Important to distinguish between:
**AgentSpeak(L++)** as the language to describe agents (knowledge and behaviour) and
**LightJason**, the Java implementation to execute agents written in AgentSpeak(L++)

-------
# Basic language elements
In imperative programming languages, e.g. Java, traffic light states could be described by:
````Java
String  light = "green";
int     phase_duration = 60;
String  phase_program = "morning";
boolean applies_to_vehicles = true;
boolean applies_to_pedestrians = false;
````
The same information in a symbolic representation:

````Java
light( green ).
phase( duration(60), program(morning) ).
appliesto( vehicles ).
~appliesto( pedestrians ).
````
----
# Plans
Plans are like static methods or functions in an imperative programming language, with an execution condition and boolean return value.
###### Example
``` java
// plan for driving vehicle
+!drive 
        //Always put semicolons between statements;
        <- vehicle/accelerate( 1 );
        //Calling the plan again, acts as a repetition loop;
        !drive
.
// backup plan if anything goes wrong when driving
-!drive 
         <- vehicle/decelerate( 1 );
         !drive
//always end a plan with a period
 .
```
---
# Strategy
**Pure strategy**: always the same strategy, insensitive to environment  e.g. I always accelerate, or I always drive with 50 km/h

**Mixed strategy**: changing based on the condition of the environment, e.g. you drive with maximum speed if there is no speed limit, and slow down to the allowed speed, otherwise

**Adaptive strategy** (advanced!): you change your strategy dynamically based on its observed performance, e.g. 
you try to learn penalty probabilities on different road segments and adapt your speed accordingly

---
# Goals

Goals define which plans an agent should try to instantiate and execute.
They can be: 
* initial goal, i.e. by convention !main.
* achievement goals inside plans, e.g. !drive
###### Example

``` java
// initial goal
!drive.
// plan for driving vehicle
+!drive 
         //action
         <- vehicle/accelerate( 1 );
         //achievement goal
         !drive
.
```
---
# Belief

Any information can be stored as a belief. A belief can be generated by
* sensors the agent uses to perceive its environment.
* agents themselves, so the agent can conclude new beliefs by combining existing ones

Beliefs can be used as context to a plan (as a precondition)
````java
!drive.
+!drive 
    // belief that there is no speedlimit (~ is negation)
    : ~>> allowedspeed(_)
    <- vehicle/accelerate( 1 );
       !drive
    //belief that there is a speedlimit
    :   >>allowedspeed(S) <- 	
        CurrentSpeed < S;
        vehicle/accelerate( 1 )
        !drive
.
````
---
# Belief
Add belief to the agent‘s beliefbase: ´+´
Whenever new information is perceived: *E.g.+ allowedspeed(S)*

Retract belief from beliefbase: ´-´ 
When a belief is no longer valid: *E.g. - allowedspeed(S)*

Update Belief: belief deletion(-) and then addition(+)
When the current belief is changed: *E.g. - allowedspeed(Oldvalue);*
*+ allowedspeed(NewValue)*


----
# Agent cycle

Agents are repeatedly executed by a runtime of the simulation.

Each time an agent is executed it runs through the agent cycle:
1. updating beliefs by perceiving the environment with sensors
2. executes all possible, i.e. instantiable plans **in parallel**

---
# The application: Traffic simulation
Game: players, rules, goal, quantifiable outcome
Players: You (ego vehicle), other participants (other vehicles)
Rules: Speed limits
Goal: Finish the course (with the best outcome possible)
Penalties: for speeding, being slow or  crashing into another vehicle

This game ***WILL*** have winners!


---
# Task 1

Use a pure strategy, to find the best possible plan to achieve your goal!

# Task 2

Use a mixed strategy, to find the best possible plan to achieve your goal!

# Task 3

Use an adaptive strategy, to find the best possible plan to achieve your goal!

---
# Competition

You have 3 tries to get the best result!

Choose one or more strategies (maximum 3)

Run the simulation

Only the smallest penalty will be taken into account

Best 3 results get a prize!



